version: '3.8'
services:
  # Partition leader election, store Kafka configuration's settings,
  # and other metadata (list of brokers, number of partitions, number of
  # replication factors), and reasignment partitions among brokers in case
  # of broker failure
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: c2c-cdc-zookeeper
    ports:
      - "2181:2181" # host_port:container_port
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      start_period: 10s
      retries: 20
      interval: 10s
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181 # Client will connect to this port to communicate with zookeeper
      ZOOKEEPER_TICK_TIME: 2000 # Basic time unit for timing (2000 ms)

  # Kafka broker, each broker can be considered as a node
  broker:
    image: confluentinc/cp-server:7.5.0
    container_name: c2c-cdc-broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    environment:
      # ID of the broker in a cluster
      KAFKA_BROKER_ID: 1 
       # Connect to Zoo Keeper for distributed coordination and leader election
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # Define how clients connect to brokers
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      # How many copies are maintained for fault tolerance
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # How long a new consumer should wait before participating in a consumer group rebalance
      # we give consumers some 
      # Schema Registry URL for storing and managing Avro schemas
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081

  # Store Avro schemas for topics to ensure schema compatibility
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: c2c-cdc-schema-registry
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8082:8081"  # Đổi cổng host từ 8081 sang 8082 để tránh trùng với Flink JobManager (sẽ dùng 8081)
    healthcheck:
      start_period: 10s
      interval: 10s
      retries: 20
      test: curl --user superUser:superUser --fail --silent --insecure http://localhost:8081/subjects --output /dev/null || exit 1
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  # Hive Metastore for Delta Lake metadata (thêm từ config trước)
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: c2c-cdc-hive-metastore
    depends_on:
      hive-postgres:
        condition: service_healthy
    ports:
      - "9083:9083"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    environment:
      SERVICE_NAME: metastore
      HIVE_METASTORE_DRIVER: org.postgresql.Driver
      HIVE_METASTORE_JDBC_URL: jdbc:postgresql://hive-postgres:5432/hive_metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hive
      HIVE_METASTORE_OPTS: "-Djava.security.egd=file:/dev/./urandom"
    volumes:
      - ./hive-conf:/opt/hive/conf  # Mount thư mục config Hive nếu cần (tạo file hive-site.xml với config metastore)

  # PostgreSQL backend cho Hive Metastore (thêm riêng để tránh xung đột với Postgres chính)
  hive-postgres:
    image: postgres:13
    container_name: c2c-cdc-hive-postgres
    ports:
      - "5433:5432"  # Đổi cổng host sang 5433 để tránh trùng với Postgres chính (5432)
    environment:
      POSTGRES_DB: loncak 
      POSTGRES_USER: loncak
      POSTGRES_PASSWORD: loncak
    volumes:
      - c2c-cdc_hive_postgres_data:/var/lib/postgresql/data
      - ./init-hive.sql:/docker-entrypoint-initdb.d/init.sql  # Script init DB cho Hive (tạo nếu cần)
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d hive_metastore"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO cho S3-compatible storage (thêm từ config Delta Lake)
  minio:
    image: minio/minio:latest
    container_name: c2c-cdc-minio
    ports:
      - "9000:9000"  # API endpoint
      - "9001:9001"  # Console
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}  # Từ config trước
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - c2c-cdc_minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Flink JobManager (thêm để tích hợp Flink với Kafka/Delta)
  flink-jobmanager:
    image: apache/flink:1.18
    container_name: c2c-cdc-flink-jobmanager
    ports:
      - "8081:8081"  # Web UI
      - "6123:6123"  # Blob server
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        rest.port: 8081
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 2
    volumes:
      - ./flink-conf:/opt/flink/conf  # Mount config Flink (thêm file delta-lake.properties từ trước)
      - c2c-cdc_flink_data:/opt/flink/data
    depends_on:
      - broker  # Để Flink kết nối Kafka
      - minio   # Để sink ra Delta Lake
      - hive-metastore

  # Flink TaskManager (thêm để chạy jobs)
  flink-taskmanager:
    image: apache/flink:1.18
    container_name: c2c-cdc-flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    scale: 1  # Có thể scale lên nhiều nếu cần
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 2
    volumes:
      - ./flink-conf:/opt/flink/conf
      - c2c-cdc_flink_data:/opt/flink/data
    ports:
      - "6122:6122"  # TaskManager RPC

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.0
    container_name: c2c-cdc-control-center
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      debezium:
        condition: service_healthy
    ports:
      - "9021:9021"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9021/healthcheck"] # Adjust the URL and options as needed
      interval: 30s
      timeout: 10s
      retries: 3
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'debezium:8083'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"  # Internal port vẫn 8081
      # How many copies for control-center internal topics
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      # Number of partitions for control-center internal topics
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      # CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      # Health check endpoint to monitor status of connectors
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      # How many copies for confluent metrics topics
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1

  # CDC platform to capture changes in DB
  # and stream them to Kafka
  debezium:
    image: debezium/connect:1.9
    container_name: c2c-cdc-debezium
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      zookeeper:
        condition: service_healthy
    healthcheck:
      test:
        [
          'CMD',
          'curl',
          '--silent',
          '--fail',
          '-X',
          'GET',
          'http://localhost:8083/connectors',
        ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: broker:29092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      # Set to Avro for higher performance
      # KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      # VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_TOPIC_CREATION_ENABLE: true

  # Debezium UI
  debezium-ui:
    image: debezium/debezium-ui:latest
    container_name: c2c-debezium-ui
    hostname: debezium-ui
    depends_on:
      debezium:
        condition: service_healthy
    ports:
      - '8080:8080'
    environment:
      KAFKA_CONNECT_URIs: http://debezium:8083

  postgresql:
    # Set wal_level from replica (default) to logical
    # so that Debezium can capture change
    image: postgres:latest
    command: ['postgres', '-c', 'wal_level=logical']
    container_name: c2c-cdc-postgresql
    healthcheck:
      test: ['CMD', 'psql', '-U', 'loncak', '-c', 'SELECT 1']
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes: 
      - c2c-cdc_postgres_data:/var/lib/postgresql/data

  trino:
    ports:
      - "8084:8080"
    container_name: c2c-cdc-trino
    image: "trinodb/trino:410"
    hostname: trino
    volumes:
      - ./trino/etc:/usr/lib/trino/etc:ro
      - ./trino/catalog:/etc/trino/catalog
    depends_on:
      - hive-metastore


volumes:
  c2c-cdc_postgres_data:
  c2c-cdc_hive_postgres_data:
  c2c-cdc_minio_data:
  c2c-cdc_flink_data: